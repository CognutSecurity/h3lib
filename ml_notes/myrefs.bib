% This file was created with JabRef 2.7b.
% Encoding: UTF8
@book{Graves2013,
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.0850v1},
author = {Graves, Alex},
eprint = {arXiv:1308.0850v1},
isbn = {2000201075},
issn = {18792782},
number = {1},
pages = {126--140},
pmid = {23459267},
title = {{Supervised Sequence Labeling with Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1308.0850},
volume = {12},
year = {2013}
}


@INPROCEEDINGS{rw06gp,
	author = {Carl Edward Rasmussen},
	title = {Gaussian processes for machine learning},
	booktitle = {},
	year = {2006},
	publisher = {MIT Press}
}

@article{mil86,
	title = "GENERALIZATION OF THE MATRIX INVERSION LEMMA.",
	author = "Tylavsky, {Daniel J.} and Sohie, {Guy R L}",
	year = "1986",
	month = "7",
	volume = "74",
	pages = "1050--1052",
	journal = "Proceedings of the IEEE",
	issn = "0018-9219",
	publisher = "Institute of Electrical and Electronics Engineers Inc.",
	number = "7",
}

@article{Chandola2009,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
	doi = {10.1145/1541880.1541882},
	eprint = {arXiv:1011.1669v3},
	isbn = {0818663359},
	issn = {0360-0300},
	journal = {ACM Computing Surveys (CSUR)},
	keywords = {Anomaly detection,outlier detection},
	number = {September},
	pages = {1--58},
	pmid = {21834704},
	title = {{Anomaly detection: A survey}},
	volume = {41},
	year = {2009}
}

@article{Hodge2004,
	abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Hodge, Victoria J. and Austin, Jim},
	doi = {10.1007/s10462-004-4304-y},
	eprint = {arXiv:1011.1669v3},
	isbn = {1856044637},
	issn = {0269-2821, 1573-7462},
	journal = {Artificial Intelligence Review},
	keywords = {anomaly,detection,deviation,noise,novelty,outlier,recognition},
	number = {1969},
	pages = {85--126},
	pmid = {24579930},
	title = {{A Survey of Outlier Detection Methodoligies}},
	volume = {22},
	year = {2004}
}



